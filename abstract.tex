We present our annotation tool for frame-by-frame video bounding box annotation.
The framework has been used in conjunction with Amazon Mechanical Turk as well as standalone, to annotate datasets for Berkeley Deep Drive and BMW.
To accomplish this, we built upon ideas from previous works in this area, and we present our improvements and optimizations upon their user interfaces.
We also introduce the idea of tuning such an annotation tool to reduce researcher's friction, which we argue is just as important as improving workers' workflow due to the high cost of researcher time.
We share our experiences with existing tools, and our ideas (and code) for how to make the experience better for researchers.
We hope our findings and contributions further reduce the cost of producing a labeled video dataset, and introduce ideas that will improve the quality of such software in the future.
